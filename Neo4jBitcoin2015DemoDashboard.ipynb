{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 6,
        "hidden": false,
        "row": 0,
        "width": 6
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "<img style=\"float: right;\" src=\"img/biva.png\" width=\"20%\">\n",
    "\n",
    "BiVA: Bitcoin Network Visualization and Analysis \n",
    "---------------\n",
    "This demo uses the database neo4j, ipython-cypher for querying neo4j using python, and python-igraph for plotting graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {}
      }
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1dd12ec58884b39b90b13d6874260d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Text(value='', layout=Layout(width='450px'), placeholder='Enter a Bitcoin addres…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83ac3ee78f1a4cb4a32b834ef3849f52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Tab(children=(HBox(children=(RadioButtons(description='View:', options=('dual mode', 'address n…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245 rows affected.\n",
      "11 rows affected.\n",
      "2 rows affected.\n",
      "1531 rows affected.\n",
      "245 rows affected.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output, display, Image\n",
    "from ipywidgets import *\n",
    " \n",
    "\n",
    "#*********************#\n",
    "#status variables\n",
    "#********************#\n",
    "#to know whether to requery the db\n",
    "current_input = 0\n",
    "#to know which graph to work with\n",
    "current_file = 0\n",
    "#to keep the same plot layout\n",
    "current_layout = 0\n",
    "#keep track of search depth\n",
    "current_depth = 0\n",
    "\n",
    "#********************#\n",
    "#Widgets: input box\n",
    "#********************#\n",
    "#to enter the Bitcoin input\n",
    "text1 = Text(\n",
    "    #description='Input:',\n",
    "    placeholder='Enter a Bitcoin address/transaction',\n",
    "    #value = '1JujBBkRGAEm7JvdnCDfGw939cEtbuuWa2',\n",
    "    layout = Layout(width='450px')\n",
    ")\n",
    "#to decide the depth of search in the database\n",
    "slider1 = IntSlider(\n",
    "    min=0,\n",
    "    max=10,\n",
    "    step=1,\n",
    "    value=3,\n",
    "    description='Search depth:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d',\n",
    "    layout = Layout(width='450px'),\n",
    "    style = {'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "#address or transaction?\n",
    "choice1 = RadioButtons(\n",
    "    options=['a Bitcoin address', 'a transaction hash'],\n",
    "    description='This is:',\n",
    "    margin = '5px',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "#create one button that indicates the user is done with the input\n",
    "button1 = Button(\n",
    "    description='Done',\n",
    "    disabled=False,\n",
    "    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    icon='check'\n",
    ")\n",
    "\n",
    "#displays the input box\n",
    "display(HBox([VBox([text1,slider1]),choice1, button1]))\n",
    "\n",
    "\n",
    "#***************#\n",
    "#Widgets: tabs\n",
    "#***************#\n",
    "#creates the first tab, the way to plot the result\n",
    "#as a function of the type of network\n",
    "choice_view = RadioButtons(\n",
    "    options=['dual mode', 'address network', 'transaction network'],\n",
    "    description='View:',\n",
    "    border ='red',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "#as a function of the search depth \n",
    "slider_zoom = interactive(plt_zoom,x=\n",
    "    IntSlider(\n",
    "    min=1,\n",
    "    max=slider1.max,\n",
    "    step=1,\n",
    "    value = slider1.value,\n",
    "    description='Zoom:',\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d',\n",
    "    layout = Layout(width='260px')\n",
    "))\n",
    "\n",
    "#with or without labels\n",
    "labelling = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Labels',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='30%')\n",
    ")\n",
    "\n",
    "tab1 = HBox([choice_view,slider_zoom,labelling],layout=Layout(height='70px'))\n",
    "\n",
    "#***************#\n",
    "#Widgets: tabs\n",
    "#***************#\n",
    "#creates the second tab, to filter edges\n",
    "text_min = Text(\n",
    "    description='BTC amt >= :',\n",
    "    value = '0',\n",
    "    layout=Layout(width='70%'))\n",
    "\n",
    "text_max = Text(\n",
    "    description='and <= :',\n",
    "    value = '10000',\n",
    "    layout=Layout(width='70%'))\n",
    "\n",
    "#creates slider)\n",
    "slider2 = IntSlider(\n",
    "    min=0,\n",
    "    max=20,\n",
    "    step=1,\n",
    "    value = slider1.value,\n",
    "    description='Depth:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "\n",
    "tab2 = HBox([VBox([text_min,text_max]),slider2],layout=Layout(height='70px'))\n",
    "\n",
    "#***************#\n",
    "#Widgets: tabs\n",
    "#***************#\n",
    "#creates the third tab, to find paths between adresses\n",
    "#input the starting point\n",
    "text_from = Text(\n",
    "    #description='From:',\n",
    "    placeholder='Choose a start addr/trans',\n",
    "    #value = text1.value,\n",
    "    layout=Layout(width='98%'))\n",
    "\n",
    "#input the end point\n",
    "text_to = Text(\n",
    "    #description='to :',\n",
    "    placeholder='and an end addr/trans',\n",
    "    layout=Layout(width='98%'))\n",
    "\n",
    "#input for path confluence\n",
    "text_addr = Textarea(\n",
    "    #description='Address :',\n",
    "    placeholder='or a list of addresses for path confluence',\n",
    "    layout=Layout(width='40%'))\n",
    "\n",
    "#choose the type of paths\n",
    "choice2 = RadioButtons(\n",
    "    options=['directed','undirected'], #'the database (undirected)'],\n",
    "    description='in:',\n",
    "    disabled=False\n",
    ")\n",
    "tab3 = HBox([VBox([text_from,text_to]),choice2,text_addr],layout=Layout(height='70px'))\n",
    "\n",
    "#***************#\n",
    "#Widgets: tabs\n",
    "#***************#\n",
    "#creates the 4rth tab, to do clustering\n",
    "#choose clustering\n",
    "choice_clus = RadioButtons(\n",
    "    options=['spectral', 'probabilistic'],\n",
    "    #description='Type:',\n",
    "    disabled=False\n",
    ")\n",
    "#parameters\n",
    "nb_clus = Text(\n",
    "    description='#clusters:',\n",
    "    value='3',\n",
    "    layout=Layout(width='130px')\n",
    ")\n",
    "alpha = Text(\n",
    "    description= r'\\(\\alpha\\)',\n",
    "    placeholder='0 or 1',\n",
    "    layout=Layout(width='140px')\n",
    ")\n",
    "dw = Text(\n",
    "    description= r'\\(D_w\\)',\n",
    "    value = '0',\n",
    "    layout=Layout(width='130px')\n",
    ")\n",
    "mu = Text(\n",
    "    description= r'\\(\\mu\\)',\n",
    "    placeholder='0 or 1',\n",
    "    layout=Layout(width='140px')\n",
    ")\n",
    "nb_iter = Text(\n",
    "    description='#iters:',\n",
    "    value='3',\n",
    "    layout=Layout(width='130px')\n",
    ")\n",
    "\n",
    "tab4 = HBox([choice_clus,nb_clus,alpha,dw,mu,nb_iter],layout=Layout(height='70px'))\n",
    "\n",
    "#***************#\n",
    "#Widgets: tabs\n",
    "#***************#\n",
    "#create text boxes\n",
    "list_neighb = Textarea(\n",
    "    description='Addresses:',\n",
    "    placeholder = 'Enter a list of addresses/transactions that you are looking for',\n",
    "    layout=Layout(width='80%',))\n",
    "\n",
    "#creates the 5th tab, to do clustering\n",
    "tab5 = VBox([list_neighb],layout=Layout(height='70px'))\n",
    "\n",
    "\n",
    "#creates the set of tabs, with the respective title\n",
    "tab = widgets.Tab([tab1, tab2, tab3, tab4, tab5],layout=Layout(width=\"95%\"))\n",
    "tab.set_title(0, 'plot')\n",
    "tab.set_title(1, 'filter edges')\n",
    "tab.set_title(2, 'find paths')\n",
    "tab.set_title(3, 'cluster')\n",
    "tab.set_title(4, 'neighbours')\n",
    "\n",
    "\n",
    "\n",
    "#**************************************#\n",
    "# create the empty space to put the plot\n",
    "#***************************************#\n",
    "from IPython.display import Image\n",
    "out = widgets.Output(layout={'border': '1px solid black','width': '95%'})\n",
    "with out:\n",
    "    display(Image(filename='img/blank.png'))\n",
    "\n",
    "#**************************************#\n",
    "# create a box to write/update comments\n",
    "#***************************************#\n",
    "out_comment = widgets.Output(layout={'width': '80%'})     \n",
    "    \n",
    "#display done button\n",
    "display(VBox([tab, out, out_comment]))\n",
    "\n",
    "#*******************************#\n",
    "#when the done button is clicked\n",
    "\n",
    "button1.on_click(handle_input)\n",
    "\n",
    "\n",
    "#3225f8f6ec52bd1a0e113ebc2dcc5208bb2c331d765efd7b4dba39d88c61bb8d\n",
    "#1DriJgHZrYYmY4jRiVQaKHzcJpUjCpGeUQ (test addr)\n",
    "#17dpY2fUTnNB7xQEA2mTcxBiZYDFN1MNGo (test another address to get a path)\n",
    "#377kST3E7qDJ1FZRoA9xZX7bK8UYCJC6Pt (not inside)\n",
    "#1JujBBkRGAEm7JvdnCDfGw939cEtbuuWa2 (scam)\n",
    "#17dpY2fUTnNB7xQEA2mTcxBiZYDFN1MNGo,19djNhJLi8ar8DCPrN7j5qr8JBytzU1kfm,1NqUXBCeVPf1QGM9K6eeVGKoLrGBdY88WC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "%load_ext cypher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 5,
        "hidden": true,
        "row": 17,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import igraph as ig\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import deque\n",
    "\n",
    "import re \n",
    "from hashlib import sha256\n",
    "\n",
    "#******************#\n",
    "# Settings\n",
    "#******************#\n",
    "max_size = 1500\n",
    "\n",
    "#********************************#\n",
    "# check bitcoin address validity\n",
    "# (code found online)\n",
    "#*******************************#\n",
    "digits58 = '123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz'\n",
    " \n",
    "def decode_base58(bc, length):\n",
    "    n = 0\n",
    "    for char in bc:\n",
    "        n = n * 58 + digits58.index(char)\n",
    "    return n.to_bytes(length, 'big')\n",
    "\n",
    "def check_bc(bc):\n",
    "    try:\n",
    "        bcbytes = decode_base58(bc, 25)\n",
    "        return bcbytes[-4:] == sha256(sha256(bcbytes[:-4]).digest()).digest()[:4]\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "#***********************************************#    \n",
    "#decides what happens once the button is clicked \n",
    "#***********************************************#    \n",
    "def handle_input(sender):\n",
    "    global current_input, current_file, current_layout, current_depth\n",
    "    \n",
    "    #**************************#\n",
    "    #db querying and basic plot\n",
    "    #**************************#\n",
    "    if tab.selected_index == 0:\n",
    "        #retrieve inputs\n",
    "        depth = slider1.value\n",
    "        labflag = labelling.value\n",
    "        #*************#\n",
    "        #db querying\n",
    "        #*************#\n",
    "        #distinguishes address and transaction, addresses first\n",
    "        if choice1.value == 'a Bitcoin address' and (not(text1.value == current_input) or not(depth == current_depth)):\n",
    "            addrvalue  = text1.value\n",
    "            if not check_bc(addrvalue):\n",
    "                raise TypeError(\"This is not a valid Bitcoin adress\")\n",
    "            else:\n",
    "                with out_comment:\n",
    "                    #if the bitcoin address is valid\n",
    "                    clear_output(wait=True)\n",
    "                    print('Please wait...querying the database...')\n",
    "                answer = query_db_addr(addrvalue,depth)\n",
    "                if len(answer) == 0 :\n",
    "                    #create an empty graph\n",
    "                    nx.write_gml(nx.Graph(), \"Gq%s.gml\" %addrvalue)\n",
    "                    with out_comment:\n",
    "                        clear_output(wait=True)\n",
    "                        print(addrvalue,\" not found.\")\n",
    "                else:\n",
    "                    current_input = text1.value\n",
    "                    current_depth = depth\n",
    "                    #export to networkx\n",
    "                    Gq = answer.get_graph()\n",
    "                    #save the data for further use\n",
    "                    nx.write_gml(Gq, \"Gq%s.gml\" %addrvalue)\n",
    "                    current_file = \"Gq%s.gml\" %addrvalue\n",
    "                    with out_comment:\n",
    "                        clear_output(wait=True)\n",
    "                        print('The network contains ',Gq.order(),' nodes and ',Gq.size(),' edges.' )\n",
    "        #transactions next\n",
    "        if choice1.value == 'a transaction hash' and not(text1.value == current_input):\n",
    "            txvalue = text1.value\n",
    "            with out_comment:\n",
    "                clear_output(wait=True)\n",
    "                print('Please wait...querying the database...')\n",
    "            answer = query_db_tx(txvalue,depth)\n",
    "            if len(answer) == 0:\n",
    "                #create an empty graph\n",
    "                nx.write_gml(nx.Graph(), \"Gq%s.gml\" %txvalue)\n",
    "                with out_comment:\n",
    "                    clear_output(wait=True)\n",
    "                    print(txvalue,\" not found.\")\n",
    "            else:\n",
    "                current_input = text1.value\n",
    "                #export to networkx\n",
    "                Gq = answer.get_graph()\n",
    "                #save the data for further use\n",
    "                nx.write_gml(Gq, \"Gq%s.gml\" %txvalue)\n",
    "                current_file = \"Gq%s.gml\" %txvalue\n",
    "                with out_comment:\n",
    "                    clear_output(wait=True)\n",
    "                    print('The network contains ',Gq.order(),' nodes and ',Gq.size(),' edges.' )\n",
    "         \n",
    "        #at this point, we have a graph Gq stored in its corresponding file\n",
    "        #*************#\n",
    "        #basic plot\n",
    "        #*************#\n",
    "        currvalue = text1.value\n",
    "        #load in networkx format\n",
    "        Gnx = nx.read_gml('Gq%s.gml' %currvalue)\n",
    "        N = Gnx.order()\n",
    "        if choice1.value == 'a Bitcoin address':\n",
    "            currtype = 'out'\n",
    "            #this is for returning after zoom\n",
    "            current_file = \"Gq%s.gml\" %currvalue\n",
    "        else:\n",
    "            currtype = 'tx'\n",
    "            #this is for returning after zoom\n",
    "            current_file = \"Gq%s.gml\" %currvalue\n",
    "        #*************#\n",
    "        #dual mode\n",
    "        #*************#\n",
    "        if choice_view.value == 'dual mode':\n",
    "            if Gnx.order() > max_size:\n",
    "                #*****************#\n",
    "                #plot a subgraph\n",
    "                #*****************#\n",
    "                distfromaddr = compd(Gnx.to_undirected(),currvalue,currtype)\n",
    "                dmax = 1\n",
    "                maxreached = False\n",
    "                while maxreached == False:\n",
    "                    nodescloserthand = [n for n in distfromaddr.keys() if distfromaddr[n] <= dmax]\n",
    "                    if len(nodescloserthand) <= max_size: \n",
    "                        dmax = dmax+1\n",
    "                    else:\n",
    "                        maxreached = True\n",
    "                Gnx.remove_nodes_from([n for n in distfromaddr.keys() if distfromaddr[n] > dmax-1])\n",
    "                nx.write_gml(Gnx, \"Gq%s.gml\" %currvalue)\n",
    "                current_file = \"Gq%s.gml\" %currvalue\n",
    "                with out_comment:\n",
    "                    print('Extracted a subnetwork of ',Gnx.order(),' nodes and ',Gnx.size(),' edges.')\n",
    "                            \n",
    "            if Gnx.order()>0:\n",
    "                #basic layout\n",
    "                G,plotstyle,all_labels = styleG(\"Gq%s.gml\" %currvalue,labflag)\n",
    "                startid = []\n",
    "                #highlights the starting address\n",
    "                if currtype == 'out':\n",
    "                    startid = [int(n['id']) for n in G.vs if n['labels']==currtype and n['addr']==currvalue]\n",
    "                #highlights the starting tx    \n",
    "                else:\n",
    "                    startid = [int(n['id']) for n in G.vs if n['labels']==currtype and n['txhash']==currvalue]\n",
    "                if len(startid)>0:\n",
    "                    for i in startid:\n",
    "                        plotstyle[\"vertex_color\"][i] = 'cyan'\n",
    "                ig.plot(G,'img/Gq%s.png' %currvalue,**plotstyle,vertex_frame_width=0)\n",
    "                current_layout = plotstyle\n",
    "                #display within widget\n",
    "                with out:\n",
    "                    clear_output(wait=True)\n",
    "                    display(Image(filename='img/Gq%s.png' %currvalue))\n",
    "\n",
    "                if labflag==True:\n",
    "                    with out_comment:\n",
    "                        clear_output(wait=True)\n",
    "                        for i in all_labels:\n",
    "                            print(i)\n",
    "            \n",
    "                    \n",
    "        #***************#\n",
    "        #single mode\n",
    "        #***************#  \n",
    "        else: \n",
    "            addrvalue  = text1.value\n",
    "            if choice_view.value == 'address network':\n",
    "                nxtype = 'out'\n",
    "            else:\n",
    "                nxtype = 'tx'\n",
    "            Gextr = extract_graph(nx.read_gml('Gq%s.gml' %currvalue),nxtype)\n",
    "            #information about the contraction is removed so it can be saved in gml format\n",
    "            for n in Gextr.nodes():\n",
    "                if 'contraction' in Gextr.node[n].keys():\n",
    "                    del Gextr.node[n]['contraction']\n",
    "            nx.write_gml(Gextr, \"Gextr%s.gml\" %currvalue)\n",
    "            current_file = \"Gextr%s.gml\" %addrvalue\n",
    "            with out_comment:\n",
    "                clear_output(wait=True)\n",
    "                print('The network contains ',Gextr.order(),' nodes')\n",
    "            #********#\n",
    "            #plot\n",
    "            #*******#\n",
    "            if Gextr.order() < max_size and Gextr.order()>0:\n",
    "                Gext,plotstyle_ext,all_labels_ext = styleG(\"Gextr%s.gml\" %currvalue,labflag)\n",
    "                startid = []\n",
    "                #highlights the starting address\n",
    "                if currtype == 'out' and nxtype == 'out':\n",
    "                    startid = [int(n['id']) for n in Gext.vs if n['labels']==currtype and n['addr']==currvalue]\n",
    "                #highlights the starting tx    \n",
    "                if currtype == 'tx' and nxtype == 'tx':\n",
    "                    startid = [int(n['id']) for n in Gext.vs if n['labels']==currtype and n['txhash']==currvalue]\n",
    "                if len(startid)>0:\n",
    "                    for i in startid:\n",
    "                        plotstyle_ext[\"vertex_color\"][i] = 'cyan'\n",
    "                #mymargin = 200\n",
    "                #mybbox = (900,600)\n",
    "                #ig.plot(G, **plotstyle,bbox = mybbox, margin =mymargin)    \n",
    "                ig.plot(Gext,'img/Gextr%s.png' %currvalue,**plotstyle_ext,vertex_frame_width=0)\n",
    "                current_layout = plotstyle_ext\n",
    "                #display within widget\n",
    "                with out:\n",
    "                    clear_output(wait=True)\n",
    "                    display(Image(filename='img/Gextr%s.png' %currvalue))\n",
    "                with out_comment:\n",
    "                        clear_output()\n",
    "                if labflag==True:\n",
    "                    with out_comment:\n",
    "                        clear_output(wait=True)\n",
    "                        for i in all_labels_ext:\n",
    "                            print(i)\n",
    "\n",
    "            \n",
    "    #**************************#\n",
    "    #edge filtering\n",
    "    #**************************#\n",
    "    if tab.selected_index == 1:\n",
    "        with out_comment:\n",
    "            clear_output(wait=True)\n",
    "            print('Please wait...querying the database...')\n",
    "        lwbnd = float(text_min.value)\n",
    "        upbnd = float(text_max.value)\n",
    "        #cypher query\n",
    "        answer = query_db_edge(text1.value,slider2.value,lwbnd,upbnd)\n",
    "        #export to networkx\n",
    "        Gq = answer.get_graph()\n",
    "        #save the data for further use\n",
    "        nx.write_gml(Gq, \"Gq%s.gml\" %text1.value)\n",
    "        with out_comment:\n",
    "            clear_output(wait=True)\n",
    "            print('The transaction network contains ',Gq.order(),' nodes and ',Gq.size(),' edges.' )\n",
    "        #********#\n",
    "        #plot\n",
    "        #********#\n",
    "        currvalue = text1.value\n",
    "        labflag = labelling.value\n",
    "        Gnx = nx.read_gml('Gq%s.gml' %currvalue)\n",
    "        if Gnx.order() < max_size and Gnx.order()>0:\n",
    "            #basic layout\n",
    "            G,plotstyle,all_labels = styleG(\"Gq%s.gml\" %currvalue,labflag)\n",
    "            startid = []\n",
    "            #highlights the starting address\n",
    "            startid = [int(n['id']) for n in G.vs if n['labels']=='out' and n['addr']==currvalue]\n",
    "            if len(startid)>0:\n",
    "                for i in startid:\n",
    "                    plotstyle[\"vertex_color\"][i] = 'cyan'\n",
    "            ig.plot(G,'img/Gq%s.png' %currvalue,**plotstyle,vertex_frame_width=0)\n",
    "            current_layout = plotstyle\n",
    "            #display within widget\n",
    "            with out:\n",
    "                clear_output(wait=True)\n",
    "                display(Image(filename='img/Gq%s.png' %currvalue))\n",
    "            with out_comment:\n",
    "                clear_output()\n",
    "            if labflag==True:\n",
    "                with out_comment:\n",
    "                    clear_output(wait=True)\n",
    "                    for i in all_labels:\n",
    "                        print(i)\n",
    "    \n",
    "    #**************************#\n",
    "    #paths\n",
    "    #**************************#\n",
    "    if tab.selected_index == 2:\n",
    "        addrvalue1 = text_from.value\n",
    "        addrvalue2 = text_to.value\n",
    "        addrvalue3 = (text_addr.value).split(',')\n",
    "        \n",
    "        if not(text_addr.value==''):\n",
    "            if not(text_from.value=='') or not(text_from.value==''):\n",
    "                with out_comment:\n",
    "                    clear_output(wait=True)\n",
    "                    print('Choose paths between addresses or path confluence.')\n",
    "            else:\n",
    "                Gnx = nx.read_gml(current_file)\n",
    "                idxlist = [n[0] for n in Gnx.nodes(data=True) if n[1]['labels']=='out' and n[1]['addr'] in addrvalue3]\n",
    "                idxlist.extend([n[0] for n in Gnx.nodes(data=True) if n[1]['labels']=='tx' and n[1]['txhash'] in addrvalue3])\n",
    "                jointPaths = findjointPath(Gnx,idxlist)\n",
    "                listJointPaths = exportJointPath(Gnx,jointPaths)\n",
    "        else:\n",
    "            pq = findpath(addrvalue1,addrvalue2)   \n",
    "            \n",
    "        Gnx = nx.read_gml(current_file)\n",
    "        if Gnx.order() < max_size:\n",
    "            #************************#\n",
    "            #draw paths\n",
    "            #***********************# \n",
    "            G=ig.Graph.Read_GML(current_file)\n",
    "            plotstyle = current_layout \n",
    "            color_dict = {\"out\": \"light blue\", \"tx\": \"pink\"}\n",
    "            plotstyle[\"vertex_color\"] = [color_dict[types] for types in G.vs[\"labels\"]]\n",
    "            \n",
    "            allpathid = []\n",
    "            if not(text_addr.value==''):\n",
    "                #path confluence\n",
    "                listnodepath = [pair[1] for pair in listJointPaths]\n",
    "                allpathid = [int(n['id']) for n in G.vs if n['labels']=='out' and n['addr'] in listnodepath]\n",
    "                allpathid.extend(int(n['id']) for n in G.vs if n['labels']=='tx' and n['txhash'] in listnodepath)\n",
    "                for j in allpathid:\n",
    "                    plotstyle[\"vertex_color\"][j] = 'maroon'\n",
    "                startid = []\n",
    "                endid = []\n",
    "                with out_comment:\n",
    "                    clear_output(wait=True)\n",
    "                    print(listnodepath)\n",
    "            else:\n",
    "                for i in range(len(pq)):     \n",
    "                    pathid = [int(n['id']) for n in G.vs if n['labels']=='out' and n['addr'] in pq[i]]\n",
    "                    pathid.extend(int(n['id']) for n in G.vs if n['labels']=='tx' and n['txhash'] in pq[i])\n",
    "                    for j in pathid:\n",
    "                        plotstyle[\"vertex_color\"][j] = 'maroon'\n",
    "                    allpathid.extend(pathid)\n",
    "                #find start and end \n",
    "                startid = [int(n['id']) for n in G.vs if n['labels']=='out' and n['addr']==addrvalue1]\n",
    "                startidtx = [int(n['id']) for n in G.vs if n['labels']=='tx' and n['txhash']==addrvalue1]\n",
    "                if len(startidtx)>0:\n",
    "                    startid.extend(startidtx)\n",
    "                endid = [int(n['id']) for n in G.vs if n['labels']=='out' and n['addr']==addrvalue2]\n",
    "                endidtx = [int(n['id']) for n in G.vs if n['labels']=='tx' and n['txhash']==addrvalue2]\n",
    "                if len(endidtx)>0:\n",
    "                    endid.extend(endidtx)\n",
    "                with out_comment:\n",
    "                    clear_output(wait=True)\n",
    "                    print('Path(s):',pq)\n",
    "                            \n",
    "            vertex_set = set(allpathid)\n",
    "            G.es[\"color\"] = [\"red\" if (edge.source in vertex_set and edge.target in vertex_set) else \"black\" for edge in G.es] \n",
    "            #otherwise the edge setting supercedes the width change\n",
    "            plotstyle.pop('edge_width', None)\n",
    "            G.es[\"width\"] = [4 if (edge.source in vertex_set and edge.target in vertex_set) else 0.5 for edge in G.es]\n",
    "                        \n",
    "            #highlights start and end (only for addresses)\n",
    "            for i in startid:\n",
    "                plotstyle[\"vertex_color\"][i] = 'yellow'\n",
    "            for i in endid:\n",
    "                plotstyle[\"vertex_color\"][i] = 'green'\n",
    "            ig.plot(G,current_file.split('.',0)[0]+'.png',**plotstyle,vertex_frame_width=0)\n",
    "                    \n",
    "            #display within widget\n",
    "            with out:\n",
    "                clear_output(wait=True)\n",
    "                display(Image(current_file.split('.',0)[0]+'.png'))\n",
    "            \n",
    "        \n",
    "    #**************************#\n",
    "    #cluster\n",
    "    #**************************#\n",
    "    if tab.selected_index == 3: \n",
    "        Gnx = nx.read_gml(current_file)\n",
    "        nbclus = int(nb_clus.value)\n",
    "        currvalue = text1.value\n",
    "        #**************************#\n",
    "        #spectral clustering\n",
    "        #**************************#\n",
    "        if choice_clus.value == 'spectral':\n",
    "            #compute spectral clustering from the adjacency matrix\n",
    "            nx.to_numpy_matrix(Gnx.to_undirected())\n",
    "            adj_mat = nx.to_numpy_matrix(Gnx.to_undirected())\n",
    "            sc = SpectralClustering(nbclus, affinity='precomputed', n_init=100)\n",
    "            sc.fit(adj_mat)\n",
    "            clusters = sc.labels_\n",
    "            #plot the result\n",
    "            Gclus,plotstyle_clus,all_labels = styleG(current_file,labelling.value)\n",
    "            pal = ig.drawing.colors.ClusterColoringPalette(nbclus)\n",
    "            for n in Gclus.vs():\n",
    "                plotstyle_clus[\"vertex_color\"][int(n['id'])] = pal.get(clusters[int(n['id'])])\n",
    "                ig.plot(Gclus,'img/Gqclus%s.png' %currvalue,**plotstyle_clus,vertex_frame_width=0)\n",
    "            with out:\n",
    "                clear_output(wait=True)\n",
    "                display(Image(filename='img/Gqclus%s.png' %currvalue))\n",
    "            with out_comment:\n",
    "                clear_output()\n",
    "        #**************************#\n",
    "        # probabilitistic clustering\n",
    "        #**************************#   \n",
    "        if choice_clus.value == 'probabilistic':\n",
    "            nbclus = int(nb_clus.value)\n",
    "            alph = int(alpha.value)\n",
    "            dwf = float(dw.value)\n",
    "            muf = int(mu.value)\n",
    "            nbiter = int(nb_iter.value)\n",
    "            Gnxinput =  nx.convert_node_labels_to_integers(Gnx, first_label=0)\n",
    "            #keep first parameters to 3 and 0.3, somehow changing 3 sometimes gives errors\n",
    "            clusters = ClusteringProbDist(Gnxinput,3,0.30,nbiter,alph,dwf,0,muf)\n",
    "            #plot the result\n",
    "            Gclus,plotstyle_clus,all_labels = styleG(current_file,labelling.value)\n",
    "            pal = ig.drawing.colors.ClusterColoringPalette(len(clusters))\n",
    "            for n in Gclus.vs():\n",
    "                idx = int(n['id'])\n",
    "                plotstyle_clus[\"vertex_color\"][idx] = pal.get([clusters.index(sblist) for sblist in clusters if idx in sblist][0])\n",
    "                ig.plot(Gclus,'img/Gqclus%s.png' %currvalue,**plotstyle_clus,vertex_frame_width=0)\n",
    "            with out:\n",
    "                clear_output(wait=True)\n",
    "                display(Image(filename='img/Gqclus%s.png' %currvalue))\n",
    "    #**************************#\n",
    "    #neighbours\n",
    "    #**************************#\n",
    "    if tab.selected_index == 4:\n",
    "        inputlist = list_neighb.value\n",
    "        list_addr = inputlist.split(',')\n",
    "\n",
    "        if choice1.value == 'a Bitcoin address':\n",
    "            currtype = 'out'\n",
    "        else:\n",
    "            currtype = 'tx'\n",
    "        addrvalue = text1.value\n",
    "        lst = findnodes(list_addr)\n",
    "    \n",
    "        with out_comment:\n",
    "            clear_output(wait=True)\n",
    "            print('Found nodes:',lst)\n",
    "        Gnx = nx.read_gml(current_file)\n",
    "        if Gnx.order() < max_size and Gnx.order()>0:\n",
    "            G=ig.Graph.Read_GML(current_file)\n",
    "            plotstyle = current_layout \n",
    "            color_dict = {\"out\": \"light blue\", \"tx\": \"pink\"}\n",
    "            plotstyle[\"vertex_color\"] = [color_dict[types] for types in G.vs[\"labels\"]]\n",
    "            #nodes of interest, typically the starting address\n",
    "            neighid = [int(n['id']) for n in G.vs if n['labels']=='out' and n['addr'] in lst]\n",
    "            neighid.extend([int(n['id']) for n in G.vs if n['labels']=='tx' and n['txhash'] in lst]) \n",
    "            for i in neighid:\n",
    "                plotstyle[\"vertex_color\"][i] = 'green'\n",
    "            ig.plot(G,current_file.split('.')[0]+'.png',**plotstyle,vertex_frame_width=0)\n",
    "            \n",
    "            #display within widget\n",
    "            with out:\n",
    "                clear_output(wait=True)\n",
    "                display(Image(current_file.split('.')[0]+'.png'))\n",
    "        \n",
    "#****************#    \n",
    "#queries neo4j\n",
    "#****************#    \n",
    "def query_db_addr(nodeid,radius):\n",
    "    #cypher query: looks for neighbours at a given radius around the address nodeid\n",
    "    #this is really stupid, should learn cypher\n",
    "    if radius == 1:\n",
    "        query = %cypher http://neo4j:neo4jpswd@localhost:7474/db/data MATCH g=(n:out {addr: {nodeid}})-[*..1]-(m) RETURN g\n",
    "    elif  radius == 2:\n",
    "        query = %cypher http://neo4j:neo4jpswd@localhost:7474/db/data MATCH g=(n:out {addr: {nodeid}})-[*..2]-(m) RETURN g\n",
    "    elif radius == 3:\n",
    "        query = %cypher http://neo4j:neo4jpswd@localhost:7474/db/data MATCH g=(n:out {addr: {nodeid}})-[*..3]-(m) RETURN g\n",
    "    elif  radius == 4:\n",
    "        query = %cypher http://neo4j:neo4jpswd@localhost:7474/db/data MATCH g=(n:out {addr: {nodeid}})-[*..4]-(m) RETURN g\n",
    "    elif  radius == 5:\n",
    "        query = %cypher http://neo4j:neo4jpswd@localhost:7474/db/data MATCH g=(n:out {addr: {nodeid}})-[*..5]-(m) RETURN g\n",
    "    elif  radius == 6:\n",
    "        query = %cypher http://neo4j:neo4jpswd@localhost:7474/db/data MATCH g=(n:out {addr: {nodeid}})-[*..6]-(m) RETURN g\n",
    "    elif  radius == 7:\n",
    "        query = %cypher http://neo4j:neo4jpswd@localhost:7474/db/data MATCH g=(n:out {addr: {nodeid}})-[*..7]-(m) RETURN g\n",
    "    elif  radius == 8:\n",
    "        query = %cypher http://neo4j:neo4jpswd@localhost:7474/db/data MATCH g=(n:out {addr: {nodeid}})-[*..8]-(m) RETURN g\n",
    "    elif  radius == 9:\n",
    "        query = %cypher http://neo4j:neo4jpswd@localhost:7474/db/data MATCH g=(n:out {addr: {nodeid}})-[*..9]-(m) RETURN g\n",
    "    else :\n",
    "        query = %cypher http://neo4j:neo4jpswd@localhost:7474/db/data MATCH g=(n:out {addr: {nodeid}})-[*..10]-(m) RETURN g\n",
    "    return query     \n",
    "\n",
    "def query_db_tx(nodeid,radius):\n",
    "    #cypher query: looks for neighbours at a given radius around the transaction nodeid\n",
    "    #this is really stupid, should learn cypher\n",
    "    if radius == 1:\n",
    "        query = %cypher http://neo4j:neo4jpswd@localhost:7474/db/data MATCH g=(n:tx {txhash: {nodeid}})-[*..1]-(m) RETURN g\n",
    "    elif radius == 2:\n",
    "        query = %cypher http://neo4j:neo4jpswd@localhost:7474/db/data MATCH g=(n:tx {txhash: {nodeid}})-[*..2]-(m) RETURN g\n",
    "    elif radius == 3:\n",
    "        query = %cypher http://neo4j:neo4jpswd@localhost:7474/db/data MATCH g=(n:tx {txhash: {nodeid}})-[*..3]-(m) RETURN g\n",
    "    elif radius == 4:\n",
    "        query = %cypher http://neo4j:neo4jpswd@localhost:7474/db/data MATCH g=(n:tx {txhash: {nodeid}})-[*..4]-(m) RETURN g\n",
    "    elif radius == 5:\n",
    "        query = %cypher http://neo4j:neo4jpswd@localhost:7474/db/data MATCH g=(n:tx {txhash: {nodeid}})-[*..5]-(m) RETURN g\n",
    "    elif radius == 6:\n",
    "        query = %cypher http://neo4j:neo4jpswd@localhost:7474/db/data MATCH g=(n:tx {txhash: {nodeid}})-[*..6]-(m) RETURN g\n",
    "    elif radius == 7:\n",
    "        query = %cypher http://neo4j:neo4jpswd@localhost:7474/db/data MATCH g=(n:tx {txhash: {nodeid}})-[*..7]-(m) RETURN g\n",
    "    elif radius == 8:\n",
    "        query = %cypher http://neo4j:neo4jpswd@localhost:7474/db/data MATCH g=(n:tx {txhash: {nodeid}})-[*..8]-(m) RETURN g\n",
    "    elif radius == 9:\n",
    "        query = %cypher http://neo4j:neo4jpswd@localhost:7474/db/data MATCH g=(n:tx {txhash: {nodeid}})-[*..9]-(m) RETURN g\n",
    "    else :\n",
    "        query = %cypher http://neo4j:neo4jpswd@localhost:7474/db/data MATCH g=(n:tx {txhash: {nodeid}})-[*..10]-(m) RETURN g\n",
    "    return query\n",
    "\n",
    "def query_db_edge(addrvalue,depth,lwbnd,upbnd):\n",
    "    #cypher query: looks for neighbours with filtered edges at a given radius around the transaction nodeid\n",
    "    #this is really stupid, should learn cypher\n",
    "    if depth == 1:\n",
    "        query = %cypher http://neo4j:neo4jpswd@localhost:7474/db/data MATCH g=(n:out {addr: {addrvalue}})-[r*..1]-(m)  WHERE ALL (z IN r WHERE (z.amount >= {lwbnd} AND z.amount <= {upbnd} ) OR z.amount IS NULL) RETURN g\n",
    "    elif  depth == 2:\n",
    "        query = %cypher http://neo4j:neo4jpswd@localhost:7474/db/data MATCH g=(n:out {addr: {addrvalue}})-[r*..2]-(m)  WHERE ALL (z IN r WHERE (z.amount >= {lwbnd} AND z.amount <= {upbnd} ) OR z.amount IS NULL) RETURN g\n",
    "    elif  depth == 3:\n",
    "        query = %cypher http://neo4j:neo4jpswd@localhost:7474/db/data MATCH g=(n:out {addr: {addrvalue}})-[r*..3]-(m)  WHERE ALL (z IN r WHERE (z.amount >= {lwbnd} AND z.amount <= {upbnd} ) OR z.amount IS NULL) RETURN g\n",
    "    elif  depth == 4:\n",
    "        query = %cypher http://neo4j:neo4jpswd@localhost:7474/db/data MATCH g=(n:out {addr: {addrvalue}})-[r*..4]-(m)  WHERE ALL (z IN r WHERE (z.amount >= {lwbnd} AND z.amount <= {upbnd} ) OR z.amount IS NULL) RETURN g\n",
    "    elif  depth == 5:\n",
    "        query = %cypher http://neo4j:neo4jpswd@localhost:7474/db/data MATCH g=(n:out {addr: {addrvalue}})-[r*..5]-(m)  WHERE ALL (z IN r WHERE (z.amount >= {lwbnd} AND z.amount <= {upbnd} ) OR z.amount IS NULL) RETURN g\n",
    "    elif  depth == 6:\n",
    "        query = %cypher http://neo4j:neo4jpswd@localhost:7474/db/data MATCH g=(n:out {addr: {addrvalue}})-[r*..6]-(m)  WHERE ALL (z IN r WHERE (z.amount >= {lwbnd} AND z.amount <= {upbnd} ) OR z.amount IS NULL) RETURN g\n",
    "    elif  depth == 7:\n",
    "        query = %cypher http://neo4j:neo4jpswd@localhost:7474/db/data MATCH g=(n:out {addr: {addrvalue}})-[r*..7]-(m)  WHERE ALL (z IN r WHERE (z.amount >= {lwbnd} AND z.amount <= {upbnd} ) OR z.amount IS NULL) RETURN g\n",
    "    elif  depth == 8:\n",
    "        query = %cypher http://neo4j:neo4jpswd@localhost:7474/db/data MATCH g=(n:out {addr: {addrvalue}})-[r*..8]-(m)  WHERE ALL (z IN r WHERE (z.amount >= {lwbnd} AND z.amount <= {upbnd} ) OR z.amount IS NULL) RETURN g\n",
    "    elif  depth == 9:\n",
    "        query = %cypher http://neo4j:neo4jpswd@localhost:7474/db/data MATCH g=(n:out {addr: {addrvalue}})-[r*..9]-(m)  WHERE ALL (z IN r WHERE (z.amount >= {lwbnd} AND z.amount <= {upbnd} ) OR z.amount IS NULL) RETURN g\n",
    "    elif depth == 10 :\n",
    "        query = %cypher http://neo4j:neo4jpswd@localhost:7474/db/data MATCH g = (n:out {addr: {addrvalue}})-[r*..10]-(m) WHERE ALL (z IN r WHERE (z.amount >= {lwbnd} AND z.amount <= {upbnd} ) OR z.amount IS NULL)  RETURN g\n",
    "    elif depth == 11:\n",
    "        query = %cypher http://neo4j:neo4jpswd@localhost:7474/db/data MATCH g=(n:out {addr: {addrvalue}})-[r*..11]-(m)  WHERE ALL (z IN r WHERE (z.amount >= {lwbnd} AND z.amount <= {upbnd} ) OR z.amount IS NULL) RETURN g\n",
    "    elif  depth == 12:\n",
    "        query = %cypher http://neo4j:neo4jpswd@localhost:7474/db/data MATCH g=(n:out {addr: {addrvalue}})-[r*..12]-(m)  WHERE ALL (z IN r WHERE (z.amount >= {lwbnd} AND z.amount <= {upbnd} ) OR z.amount IS NULL) RETURN g\n",
    "    elif  depth == 13:\n",
    "        query = %cypher http://neo4j:neo4jpswd@localhost:7474/db/data MATCH g=(n:out {addr: {addrvalue}})-[r*..13]-(m)  WHERE ALL (z IN r WHERE (z.amount >= {lwbnd} AND z.amount <= {upbnd} ) OR z.amount IS NULL) RETURN g\n",
    "    elif  depth == 14:\n",
    "        query = %cypher http://neo4j:neo4jpswd@localhost:7474/db/data MATCH g=(n:out {addr: {addrvalue}})-[r*..14]-(m)  WHERE ALL (z IN r WHERE (z.amount >= {lwbnd} AND z.amount <= {upbnd} ) OR z.amount IS NULL) RETURN g\n",
    "    elif  depth == 15:\n",
    "        query = %cypher http://neo4j:neo4jpswd@localhost:7474/db/data MATCH g=(n:out {addr: {addrvalue}})-[r*..15]-(m)  WHERE ALL (z IN r WHERE (z.amount >= {lwbnd} AND z.amount <= {upbnd} ) OR z.amount IS NULL) RETURN g\n",
    "    elif  depth == 16:\n",
    "        query = %cypher http://neo4j:neo4jpswd@localhost:7474/db/data MATCH g=(n:out {addr: {addrvalue}})-[r*..16]-(m)  WHERE ALL (z IN r WHERE (z.amount >= {lwbnd} AND z.amount <= {upbnd} ) OR z.amount IS NULL) RETURN g\n",
    "    elif  depth == 17:\n",
    "        query = %cypher http://neo4j:neo4jpswd@localhost:7474/db/data MATCH g=(n:out {addr: {addrvalue}})-[r*..17]-(m)  WHERE ALL (z IN r WHERE (z.amount >= {lwbnd} AND z.amount <= {upbnd} ) OR z.amount IS NULL) RETURN g\n",
    "    elif  depth == 18:\n",
    "        query = %cypher http://neo4j:neo4jpswd@localhost:7474/db/data MATCH g=(n:out {addr: {addrvalue}})-[r*..18]-(m)  WHERE ALL (z IN r WHERE (z.amount >= {lwbnd} AND z.amount <= {upbnd} ) OR z.amount IS NULL) RETURN g\n",
    "    elif  depth == 19:\n",
    "        query = %cypher http://neo4j:neo4jpswd@localhost:7474/db/data MATCH g=(n:out {addr: {addrvalue}})-[r*..19]-(m)  WHERE ALL (z IN r WHERE (z.amount >= {lwbnd} AND z.amount <= {upbnd} ) OR z.amount IS NULL) RETURN g\n",
    "    else :\n",
    "        query = %cypher http://neo4j:neo4jpswd@localhost:7474/db/data MATCH g = (n:out {addr: {addrvalue}})-[r*..20]-(m) WHERE ALL (z IN r WHERE (z.amount >= {lwbnd} AND z.amount <= {upbnd} ) OR z.amount IS NULL)  RETURN g\n",
    "    return query\n",
    "\n",
    "#*****************#\n",
    "# plot with igraph\n",
    "#*****************#\n",
    "def styleG(fileG,l):\n",
    "    #**********************************************#\n",
    "    #fileG is the name of the file to be read\n",
    "    #l is a flag for labels: True = label, False = no label\n",
    "    #**********************************************#\n",
    "    G=ig.Graph.Read_GML(fileG)\n",
    "    #kamada-kawai layout\n",
    "    layt=G.layout('kk') \n",
    "    #style\n",
    "    visual_style = {}\n",
    "    visual_style[\"layout\"] = layt\n",
    "    nbv = len(G.vs)\n",
    "    visual_style[\"vertex_size\"] = max(1,round(10/math.log10(10)))\n",
    "    #see x11 color names\n",
    "    color_dict = {\"out\": \"light blue\", \"tx\": \"pink\"}\n",
    "    visual_style[\"vertex_color\"] = [color_dict[types] for types in G.vs[\"labels\"]]\n",
    "    visual_style[\"bbox\"] = (600, 500)\n",
    "    \n",
    "    #add labels\n",
    "    lst_labels = []\n",
    "    if l==True: \n",
    "        #label with integers    \n",
    "        visual_style[\"vertex_label\"] = [str(int(l)) for l in G.vs[\"id\"]]\n",
    "        #label by txid and addr\n",
    "        lst_labels = [(int(n['id']),n['txhash']) if n['labels']=='tx' else (int(n['id']),n['addr']) for n in G.vs]\n",
    "        #visual_style[\"vertex_label\"] = [n['txhash'] if n['labels']=='tx' \\\n",
    "        #                                else n['addr'] for n in G.vs ]\n",
    "        #visual_style[\"vertex_label\"] = [n['txhash'] if n['labels']=='tx' \\\n",
    "        #                                else ' ' for n in G.vs ]\n",
    "    else:\n",
    "        #no label\n",
    "        visual_style[\"vertex_label\"] = [' ' for l in G.vs[\"id\"]]\n",
    "    \n",
    "    visual_style[\"edge_width\"] = 0.3\n",
    "    visual_style[\"edge_arrow_size\"] = [0.5 for e in G.es]\n",
    "    return G,visual_style,lst_labels\n",
    "\n",
    "#************************************#\n",
    "# refresh plot with zoom and interact\n",
    "#************************************#\n",
    "def plt_zoom(x):\n",
    "    global current_file\n",
    "    if not(current_file == 0) and choice_view.value == 'dual mode' :\n",
    "        if x<slider1.value:\n",
    "            currvalue = current_file.split('.')[0][2:]\n",
    "            Gnx = nx.read_gml(current_file)\n",
    "            if choice1.value == 'a Bitcoin address':\n",
    "                currtype = 'out'\n",
    "            else:\n",
    "                currtype = 'tx'\n",
    "            #compute distances\n",
    "            distfromaddr = compd(Gnx.to_undirected(),currvalue,currtype)\n",
    "            #write data\n",
    "            Gnx.remove_nodes_from([n for n in distfromaddr.keys() if distfromaddr[n] > x])\n",
    "            nx.write_gml(Gnx, \"Gqz%s.gml\" %currvalue)\n",
    "            #load for plotting\n",
    "            G=ig.Graph.Read_GML(current_file)\n",
    "            Gz=ig.Graph.Read_GML(\"Gqz%s.gml\" %currvalue)\n",
    "            Gz_addr_tx = [n['addr'] if n['labels']=='out' else n['txhash'] for n in Gz.vs]\n",
    "            far_nodes = []\n",
    "            l1 = [n for n in G.vs if n['labels'] == 'out']\n",
    "            l2 = [n for n in G.vs if n['labels'] == 'tx']        \n",
    "            far_nodes = [int(n['id']) for n in l1 if not(n['addr'] in Gz_addr_tx)]\n",
    "            far_nodes.extend([int(n['id']) for n in l2 if not(n['txhash'] in Gz_addr_tx)])\n",
    "            plotstyle_zoom  = current_layout\n",
    "            color_dict = {\"out\": \"light blue\", \"tx\": \"pink\"}\n",
    "            plotstyle_zoom[\"vertex_color\"] = [color_dict[types] for types in G.vs[\"labels\"]]\n",
    "            if currtype == 'out':\n",
    "                startid = [int(n['id']) for n in G.vs if n['labels']=='out' and n['addr']==currvalue]\n",
    "                if len(startid)>0:\n",
    "                    for i in startid:\n",
    "                        plotstyle_zoom[\"vertex_color\"][i] = 'cyan'\n",
    "            if len(far_nodes)>0:\n",
    "                for i in far_nodes:\n",
    "                    plotstyle_zoom[\"vertex_color\"][i] = 'white'\n",
    "                    plotstyle_zoom[\"vertex_label\"][i] = ' '\n",
    "            plotstyle_zoom[\"edge_width\"] = [0 if (edge.source in far_nodes or edge.target in far_nodes) else 0.3 for edge in G.es]\n",
    "            plotstyle_zoom[\"edge_arrow_size\"] = [0 if (edge.source in far_nodes or edge.target in far_nodes) else 0.5 for edge in G.es] \n",
    "            ig.plot(G,'img/Gqz%s.png' %currvalue,**plotstyle_zoom,vertex_frame_width=0)\n",
    "            with out: \n",
    "                clear_output(wait=True)\n",
    "                display(Image(filename='img/Gqz%s.png' %currvalue))\n",
    "        else:\n",
    "            currvalue = current_file.split('.')[0][2:]\n",
    "            G=ig.Graph.Read_GML(current_file)\n",
    "            plotstyle_zoom  = current_layout\n",
    "            color_dict = {\"out\": \"light blue\", \"tx\": \"pink\"}\n",
    "            plotstyle_zoom[\"vertex_color\"] = [color_dict[types] for types in G.vs[\"labels\"]]\n",
    "            plotstyle_zoom[\"edge_width\"] = 0.3\n",
    "            plotstyle_zoom[\"edge_arrow_size\"] = 0.5\n",
    "            ig.plot(G,'img/Gq%s.png' %currvalue,**plotstyle_zoom,vertex_frame_width=0)\n",
    "            with out:\n",
    "                clear_output(wait=True)\n",
    "                display(Image(filename='img/Gq%s.png' %currvalue))\n",
    "\n",
    "\n",
    "#**************************************#\n",
    "#extracts transaction/address network\n",
    "#**************************************#\n",
    "def extract_graph(G,label):\n",
    "    #G is the graph read from gml format\n",
    "    #label is either 'tx' or 'out'\n",
    "    listedges = list(G.edges())\n",
    "    listsubedges = []\n",
    "    \n",
    "    #extract IDs of transaction/output nodes\n",
    "    keptnodes =  [n[0] for n in list(G.nodes(data=True)) if n[1]['labels']==label]\n",
    "    \n",
    "    for u in keptnodes:\n",
    "        listneighb_u = [listedges[n][1] for n in range(len(listedges)) if listedges[n][0] == u ]\n",
    "        for v in listneighb_u:\n",
    "            listnewedges = [(u,listedges[n][1]) for n in range(len(listedges)) if listedges[n][0] == v and listedges[n][1] in keptnodes]\n",
    "            listsubedges.extend(listnewedges)\n",
    "    \n",
    "    Gnew =nx.DiGraph()\n",
    "    #nodes, they are added separately from edges in case there are isolated nodes\n",
    "    Gnew.add_nodes_from([n for n in list(G.nodes(data=True)) if n[1]['labels']==label])\n",
    "    #edges\n",
    "    Gnew.add_edges_from(listsubedges)\n",
    "    \n",
    "    if label == 'out':\n",
    "        #merges the same addresses\n",
    "        addr_map = defaultdict(list)\n",
    "        #identifies repeated addresses\n",
    "        for n in list(Gnew.nodes(data=True)):\n",
    "            addr_map[n[1]['addr']].append(n[0])\n",
    "\n",
    "        #for each repeated address, find node identifiers\n",
    "        for key in addr_map.keys():\n",
    "            ll = addr_map[key]\n",
    "            if len(ll) > 1:\n",
    "                #contract repeated addresses pairwise\n",
    "                for n in ll[1:]:\n",
    "                    Gnew = nx.contracted_nodes(Gnew,ll[0],n)\n",
    "    \n",
    "    return Gnew\n",
    "\n",
    "#**********************************#\n",
    "#find paths between two addresses\n",
    "#**********************************#\n",
    "def findpath(addrvalue1,addrvalue2):\n",
    "    #\n",
    "    Gnx = nx.read_gml(current_file)\n",
    "    if check_bc(addrvalue1): \n",
    "        nodeid1 = [n for n in list(Gnx.nodes()) if Gnx.nodes(data=True)[n]['labels']=='out' and Gnx.nodes(data=True)[n]['addr']==addrvalue1]\n",
    "    else:\n",
    "        nodeid1 = [n for n in list(Gnx.nodes()) if Gnx.nodes(data=True)[n]['labels']=='tx' and Gnx.nodes(data=True)[n]['txhash']==addrvalue1]\n",
    "   \n",
    "    if check_bc(addrvalue2):\n",
    "        nodeid2 = [n for n in list(Gnx.nodes()) if Gnx.nodes(data=True)[n]['labels']=='out' and Gnx.nodes(data=True)[n]['addr']==addrvalue2]\n",
    "    else:\n",
    "        nodeid2 = [n for n in list(Gnx.nodes()) if Gnx.nodes(data=True)[n]['labels']=='tx' and Gnx.nodes(data=True)[n]['txhash']==addrvalue2]\n",
    "\n",
    "    ppall = []\n",
    "\n",
    "    for addr1 in nodeid1:\n",
    "        for addr2 in nodeid2:\n",
    "            if choice2.value == 'undirected': \n",
    "                pt = nx.shortest_path(Gnx.to_undirected(),addr1,addr2)\n",
    "            if choice2.value == 'directed': \n",
    "                try:\n",
    "                    pt = nx.shortest_path(Gnx,addr1,addr2)\n",
    "                except nx.NetworkXNoPath:\n",
    "                    with out_comment:\n",
    "                        print(\"No directed path.\")\n",
    "                    pt = []\n",
    "                        \n",
    "            ppt = []                      \n",
    "            for n in pt:\n",
    "                if 'addr' in Gnx.nodes(data=True)[n].keys():\n",
    "                    ppt.append(Gnx.nodes(data=True)[n]['addr'])\n",
    "                else:\n",
    "                    ppt.append(Gnx.nodes(data=True)[n]['txhash'])              \n",
    "            ppall.append(ppt)\n",
    "\n",
    "    return ppall \n",
    "\n",
    "#***************************#\n",
    "#find neighbours\n",
    "#***************************#\n",
    "def findnodes(listaddr):\n",
    "    \n",
    "    addrvalue = text1.value\n",
    "    Gnx = nx.read_gml('Gq%s.gml' %addrvalue)\n",
    "    listinG = [n[1]['addr'] for n in list(Gnx.nodes(data=True)) if n[1]['labels']=='out'] \n",
    "    listinG.extend([n[1]['txhash'] for n in list(Gnx.nodes(data=True)) if n[1]['labels']=='tx'])\n",
    "    \n",
    "    return [addr for addr in listaddr if addr in listinG]\n",
    "\n",
    "\n",
    "#*************************************#\n",
    "#compute which nodes at which distance\n",
    "#*************************************#\n",
    "def compd(currG,currvalue,currtype):\n",
    "    #currtype is either 'tx' or 'out'\n",
    "    #compute distances from nodes of interest\n",
    "    if currtype == 'out':\n",
    "        nodeid = [n for n in list(currG.nodes()) if currG.nodes(data=True)[n]['labels']=='out' and currG.nodes(data=True)[n]['addr']==currvalue]\n",
    "    else:\n",
    "        nodeid = [n for n in list(currG.nodes()) if currG.nodes(data=True)[n]['labels']=='tx' and currG.nodes(data=True)[n]['txhash']==currvalue]\n",
    "        \n",
    "    #create a dictionary to store the closest distance between any node and different instances of the same addr\n",
    "    at_dist = {}\n",
    "    for n in currG.nodes():\n",
    "        at_dist[n] = 10000\n",
    "    #computes distances from chosen node\n",
    "    for id in nodeid: \n",
    "        pathlen = nx.single_source_shortest_path_length(currG,id) \n",
    "        for n in pathlen.keys():\n",
    "            at_dist[n] = min(at_dist[n],pathlen[n])\n",
    "    return at_dist \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import operator\n",
    "import random\n",
    "from sklearn import cluster\n",
    "\n",
    "#******************************#\n",
    "#Bui's code for path confluence\n",
    "#******************************#\n",
    "\n",
    "def BFS_findjoin(s,G,successors,cutoff):\n",
    "    #written by Phetsouvanh Silivanxay\n",
    "    # Create a queue for BFS\n",
    "    queue = deque()\n",
    "    visited = set()\n",
    "    # Mark the source node as \n",
    "    # visited and enqueue it\n",
    "    queue.append(s)\n",
    "    level = 0\n",
    "    numChild = 1;\n",
    "    numNewChild = 0;\n",
    "    nodeCount = 0;\n",
    "    while queue:\n",
    "        node = queue.popleft()\n",
    "        iteration = []\n",
    "        if( successors):\n",
    "            iteration = G.successors(node)\n",
    "            \n",
    "        else:\n",
    "            iteration = G.predecessors(node)\n",
    "        for neighbor in iteration:\n",
    "            if neighbor not in visited:\n",
    "                numNewChild+=1;\n",
    "                queue.append(neighbor)\n",
    "                visited.add(neighbor)\n",
    "            elif neighbor != node and node!=s and neighbor in visited:\n",
    "                return neighbor\n",
    "        nodeCount+=1;\n",
    "        if( nodeCount == numChild):\n",
    "            level+=1\n",
    "            numChild = numNewChild;\n",
    "            if(level==cutoff):\n",
    "                return \"empty\"\n",
    "        \n",
    "\n",
    "    return \"empty\"\n",
    "\n",
    "def findjointPath(Kcg,extracted_addr):\n",
    "    #written by Phetsouvanh Silivanxay\n",
    "    Kcg_u = Kcg.to_undirected()\n",
    "    shortest_paths = []\n",
    "    for sourceAddr in extracted_addr:\n",
    "        for destinationAddr in extracted_addr:\n",
    "            if ( sourceAddr!=destinationAddr):\n",
    "                try:\n",
    "                    paths =nx.all_shortest_paths(Kcg_u, sourceAddr, destinationAddr)\n",
    "                    for path in paths:\n",
    "                        shortest_paths.append(path)\n",
    "                except nx.exception.NodeNotFound:\n",
    "                    pass\n",
    "                except nx.exception.NetworkXNoPath:\n",
    "                    pass\n",
    "    \n",
    "    \n",
    "    endNode = []\n",
    "    startNode = []\n",
    "    countt=0\n",
    "    \n",
    "    jointPaths = []\n",
    "    for path in shortest_paths:\n",
    "        if len(path) >2:\n",
    "            for i in range(len(path)-2):\n",
    "                pre = path[i]\n",
    "                mid = path[i+1]\n",
    "                suc = path[i+2]\n",
    "                if (pre in Kcg.predecessors(mid) and suc in Kcg.predecessors(mid)):\n",
    "                    endNode.append(mid)\n",
    "                    paths = []\n",
    "                    node = BFS_findjoin(mid,Kcg,False,10)\n",
    "                    if  (node !='empty'):\n",
    "                        paths = nx.all_simple_paths(Kcg, source=node, target=mid, cutoff=10)\n",
    "                        paths = list (paths)\n",
    "                    if( paths != []):\n",
    "                        paths[0] = paths[0]+path\n",
    "                        jointPaths.append(paths)\n",
    "                elif (pre in Kcg.successors(mid) and suc in Kcg.successors(mid)):\n",
    "                    startNode.append(mid)\n",
    "                    end = BFS_findjoin(mid,Kcg,True,10)\n",
    "                    paths = []\n",
    "                    if  (end !='empty'):\n",
    "                        paths = nx.all_simple_paths(Kcg, source=mid, target=end, cutoff=1)\n",
    "                        paths = list (paths)\n",
    "                    if( paths != []):\n",
    "                        paths[0] = paths[0]+path\n",
    "                        jointPaths.append(paths)\n",
    "        countt+=1\n",
    "    endNode = set(endNode)\n",
    "    startNode = set(startNode)\n",
    "    #print ('endNode:',endNode)\n",
    "    #print ('startNode:',startNode)    \n",
    "    \n",
    "    nodesAlongPaths = set()\n",
    "    for multipaths in jointPaths:\n",
    "        for path in multipaths:\n",
    "            for address in path:\n",
    "                nodesAlongPaths.add(address)\n",
    "    #print ('nodesAlongPaths:',nodesAlongPaths)\n",
    "\n",
    "    \n",
    "    return jointPaths\n",
    "\n",
    "def exportJointPath(Kcg,jointPaths):\n",
    "    #modified to return instead of write\n",
    "    visited = set()\n",
    "    pathlist = []\n",
    "    for idn, label in Kcg._node.items():\n",
    "        count = 1\n",
    "        for multipaths in jointPaths:\n",
    "            tmplist = []\n",
    "            for path in multipaths:\n",
    "                if (idn in path and idn not in visited):\n",
    "                    #print({'Id': idn, 'JointPath':count})\n",
    "                    if 'addr' in label.keys():\n",
    "                        tmplist.append((idn,label['addr']))\n",
    "                    if 'txhash' in label.keys():\n",
    "                        tmplist.append((idn,label['txhash']))\n",
    "                    visited.add(idn)\n",
    "            count +=1\n",
    "            pathlist.extend(tmplist)\n",
    "    return pathlist \n",
    "\n",
    "#******************************#\n",
    "#Bui's code for clustering\n",
    "#******************************#\n",
    "\n",
    "def ClusteringProbDist(Kcg,num_cluster,topN,iter,alpha,dw,t,mu_f):\n",
    "    #written by Phetsouvanh Silivanxay\n",
    "    tt = time.time()\n",
    "    N = Kcg.order()\n",
    "    #Pkcg, D = MatrixWithAuxilary(Kcg,w)\n",
    "    #Pkcg, D = MatrixWithAuxilaryFanOut(Kcg,w)\n",
    "    #Hinf, mt = Hijt(Pkcg,D,t)\n",
    "\n",
    "    # mt is probablity matrix\n",
    "    #Hinf,mt = Hijinf(Pkcg,D)\n",
    "    Hinf,mt,Pkcg = Ht(Kcg, alpha,dw,t,mu_f)\n",
    "\n",
    "    #seelct query nodes from bottom n entropy value\n",
    "    includedSet = []\n",
    "    queryNodesClusterAggreation = []\n",
    "    \n",
    "    TopEntropyNodes = getBottomN(Hinf,int(N*topN),True)\n",
    "\n",
    "    remainingNodes = getRemainingNodeSortedBylowestEntropy(Kcg,includedSet,Hinf,False)\n",
    "\n",
    "    exceptionNodes = []\n",
    "    while(len(remainingNodes) > 0):\n",
    "        queryNodes = []\n",
    "        for remainingNode in remainingNodes:\n",
    "            queryNodes.append(remainingNode)\n",
    "            break\n",
    "        #print('queryNodes',queryNodes)\n",
    "        queryNodesCluster = getQueryNodeCluster(queryNodes,N,mt,num_cluster)\n",
    "        queryNodesCluster = getValidQueryNodeCluster(queryNodesCluster,TopEntropyNodes,queryNodes,exceptionNodes,mt,queryNodesClusterAggreation)\n",
    "\n",
    "        queryNodesCluster.extend(queryNodesClusterAggreation)\n",
    "        queryNodesClusterAggreation, includedSet = ClusterAggregation(queryNodesCluster)\n",
    "        includedSet = includedSet.union(exceptionNodes)\n",
    "\n",
    "        for eachNode in includedSet:\n",
    "            if ( eachNode in includedSet and eachNode in remainingNodes):\n",
    "                remainingNodes.remove(eachNode)\n",
    "\n",
    "    \n",
    "    clusters = queryNodesClusterAggreation\n",
    "    #print ('seeds.append (',queryNodesClusterAggreation,')')\n",
    "    for i in range (iter):\n",
    "        #print ('round:', i)\n",
    "        queryNodesClusterAggreation =ClusterAgglomertion(clusters, mt, num_cluster,Hinf,Pkcg)\n",
    "        clusters = queryNodesClusterAggreation\n",
    "        #print ('final:',clusters)\n",
    "    \n",
    "    \n",
    "    elapsed = time.time() - tt\n",
    "    with out_comment: \n",
    "        print('Complete  time in secs',elapsed)\n",
    "    return clusters\n",
    "\n",
    "def Ht(G,alpha,dw,t,mu_f):\n",
    "    tt = time.time()\n",
    "    #G is the graph, nodes must be labelled by integers starting from 0, \n",
    "    #use nx.convert_node_labels_to_integers(G, first_label=0) if needed\n",
    "    #\n",
    "    #alpha is a flag: \n",
    "    #alpha = 0 means the graph is considered unweighted, i.e. alpha(w(e)) = 1 for all edges e \n",
    "    #use alpha = 0 if the graph is actually unweighted\n",
    "    #alpha = 1 means that we use the weights of the graph, i.e. alpha(w(e)) = w(e) for all edges e\n",
    "    #\n",
    "    #dw defines the matrix of auxiliary probabilities \n",
    "    #dw = 0 means that the function Dunif is called\n",
    "    #dw > 0 means that dw*I is used as the matrix\n",
    "    #\n",
    "    #t is the time, if t==0, the asymptotic behaviour is computed\n",
    "    #\n",
    "    #mu_f is a flag:\n",
    "    #mu_f = 0 means that we use a non-weighted entropy\n",
    "    #mu_f = 1 means that we use an entropy weighted by the ratio of weighted out-degree by degree\n",
    "    #mu_f = 2 means that we use an entropy weighted by the ratio of log2 weighted out-degree by log2 degree\n",
    "\n",
    "    #number of nodes\n",
    "    n = G.order()\n",
    "    \n",
    "    def Dunif(G,alpha):\n",
    "        #compute the auxiliary probabilities in a way which is proportional to the weighted degree \n",
    "        n = G.order()\n",
    "        if alpha == 0:\n",
    "            Du = np.zeros((n,n))\n",
    "            for i in range(n):\n",
    "                li = list(G[i].keys())\n",
    "                #nb of neighbours + self-loop + auxiliary node\n",
    "                Du[i][i] = 1/(len(li)+2)\n",
    "\n",
    "            \n",
    "        if alpha == 1:\n",
    "            Du = np.zeros((n,n))\n",
    "            #list containing the weighted (out-)degrees\n",
    "            if nx.is_directed(G):\n",
    "                weighted_deg = G.out_degree(weight='weight')\n",
    "            else:\n",
    "                weighted_deg = G.degree(weight='weight')\n",
    "            for i in range(n):\n",
    "                li = list(G[i].keys())\n",
    "                #nb of neighbours + self-loop + auxiliary node\n",
    "                Du[i][i] = 1/(weighted_deg[i]+2)       \n",
    "        \n",
    "        return Du\n",
    "    \n",
    "    #compute the transition probability matrices P and Ptilde\n",
    "    #matrix of probabilities\n",
    "    P = np.zeros((n,n))\n",
    "    #initialize Ptilde\n",
    "    Pt = np.zeros((n,n))\n",
    "    #adjacency matrix and self-loops added\n",
    "    A = nx.to_numpy_matrix(G)+np.identity(n)\n",
    "    \n",
    "    #computes the matrix of auxiliary probabilities\n",
    "    D = []\n",
    "    if dw == 0:\n",
    "        D = Dunif(G,alpha)\n",
    "    else: \n",
    "        D = dw*np.identity(n)\n",
    "    \n",
    "   \n",
    "    \n",
    "    if alpha == 0:\n",
    "        for i in range(n):\n",
    "            li = list(G[i].keys())\n",
    "            for j in range(n):\n",
    "                if not(A[i].getA()[0][j] == 0):\n",
    "                    P[i][j] = 1/(len(li)+1)    \n",
    "                    Pt[i][j] = P[i][j] - D[i][i]/(len(li)+1)\n",
    "    weighted_deg = []\n",
    "    if alpha == 1:\n",
    "        #list containing the weighted (out-)degrees\n",
    "        if nx.is_directed(G):\n",
    "            weighted_deg = G.out_degree(weight='weight')\n",
    "        else:\n",
    "            weighted_deg = G.degree(weight='weight')\n",
    "        \n",
    "        for i in range(n):\n",
    "            li = list(G[i].keys())\n",
    "            for j in range(n):\n",
    "                Aij = A[i].getA()[0][j]\n",
    "                if not(Aij == 0):\n",
    "                    #a weight of 1 is given to the self-loop\n",
    "                    P[i][j] = Aij/(weighted_deg[i]+1)\n",
    "                    Pt[i][j] = P[i][j] -D[i][i]*Aij/(weighted_deg[i]+1)\n",
    "                    #Pt[i][j] = P[i][j] - D[i][i]/(len(li)+1)\n",
    "                    \n",
    "\n",
    "    #m contains the modified version of P, Ptilde  \n",
    "    mup = np.hstack((Pt, D))\n",
    "    \n",
    "    mdown = np.hstack((np.zeros((n,n)), np.identity(n)))\n",
    "    m = np.vstack((mup,mdown))\n",
    "    \n",
    "    #distinguish finite from asymptotic values of t\n",
    "    if t == 0:\n",
    "        #asymptotic case        \n",
    "        mt = np.matmul(np.linalg.inv(np.identity(n)-Pt),D)\n",
    "    else: \n",
    "        mt = np.linalg.matrix_power(m,t)\n",
    "   \n",
    "    #define the weight mu for each node\n",
    "    mu = []\n",
    "    if mu_f == 0:\n",
    "        mu = np.ones(n)\n",
    "        \n",
    "    if mu_f == 1:\n",
    "        for u in G.nodes():\n",
    "            dwout = sum([G[u][v]['weight'] for v in G.successors(u)])\n",
    "            if not(dwout == G.out_degree(u)): \n",
    "                #ratio of degree as weight\n",
    "                mu.append(dwout/G.out_degree(u))\n",
    "            else:\n",
    "                mu.append(1)\n",
    "       \n",
    "    if mu_f == 2:\n",
    "        for u in G.nodes():\n",
    "            dwout = sum([G[u][v]['weight'] for v in G.successors(u)])\n",
    "            if not(dwout == G.out_degree(u)): \n",
    "                #ratio of entropic centralities as weight\n",
    "                mu.append(np.log2(dwout)/np.log2(G.out_degree(u)))\n",
    "            else:\n",
    "                mu.append(1) \n",
    "    \n",
    "    #initialize entropy vector\n",
    "    H = [0 for k in range(n)];\n",
    "    if t == 0:\n",
    "        #asymptotic case\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                pij = mt[i][j] \n",
    "                if pij != 0:\n",
    "                    #handles numerical approximation of zero\n",
    "                    if abs(pij)> 1.0e-14:\n",
    "                        H[i] = H[i] - pij*np.log2(pij)*mu[j]\n",
    "    else:\n",
    "        #finite case\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                pij = mt[i][j] + mt[i][n+j]\n",
    "                if pij != 0:\n",
    "                    H[i] = H[i] - pij*np.log2(pij)*mu[j]\n",
    "                    \n",
    "    elapsed = time.time() - tt\n",
    "    #print('time in secs',elapsed)\n",
    "    return H,mt,P\n",
    "\n",
    "def getBottomN(H,n,rev):\n",
    "    #written by Phetsouvanh Silivanxay\n",
    "    H_dict= dict()\n",
    "    for i in range (len(H)):\n",
    "        H_dict[i] = H[i]\n",
    "    count = 0\n",
    "    output = []\n",
    "    for key, value in sorted(H_dict.items(), key=operator.itemgetter(1),reverse=rev):\n",
    "        if(count == n):\n",
    "            break\n",
    "        output.append(key)\n",
    "        count = count+1\n",
    "\n",
    "    return output\n",
    "\n",
    "def getRemainingNodeSortedBylowestEntropy(Kcg,includedSet,H,rev):\n",
    "    #written by Phetsouvanh Silivanxay\n",
    "    H_dict= dict()\n",
    "    for i in range (len(H)):\n",
    "        H_dict[i] = H[i]\n",
    "    count = 0\n",
    "    remainingNodes = []\n",
    "    for node , value in sorted(H_dict.items(), key=operator.itemgetter(1),reverse=rev):\n",
    "        if node not in includedSet:\n",
    "            remainingNodes.append(node)\n",
    "    return remainingNodes\n",
    "\n",
    "def getQueryNodeCluster(queryNodes,N,mt,num_cluster):\n",
    "    #written by Phetsouvanh Silivanxay\n",
    "    queryNodesCluster =[]\n",
    "    for queryNode in queryNodes:\n",
    "        probDist = []\n",
    "        indxedClusters, maxIndex = findProbdistClusterWithQueryNode(mt,num_cluster,queryNode,N)\n",
    "        #print ('mini result',maxIndex, indxedClusters[maxIndex])\n",
    "        queryNodesCluster.append(indxedClusters[maxIndex])\n",
    "    \n",
    "    return queryNodesCluster\n",
    "\n",
    "def getValidQueryNodeCluster(queryNodesCluster,TopEntropyNodes,queryNodes,exceptionNodes,mt,queryNodesClusterAggreation):\n",
    "    #written by Phetsouvanh Silivanxay\n",
    "    validCluster = []\n",
    "    count = 0;\n",
    "    for cluster in queryNodesCluster:\n",
    "        numOfHighEntropy = 0\n",
    "        highEntropyNode = []\n",
    "        maxProb = 0\n",
    "        maxProbNode = 0\n",
    "        countMajority = dict()\n",
    "        isContainedAllTopEntropy = isContainedAllTopEntropyNodes(TopEntropyNodes, queryNodes[count],cluster)\n",
    "        \n",
    "        for i in range (len(queryNodesClusterAggreation)):\n",
    "            countMajority[i] = 0\n",
    "        for node in cluster:\n",
    "            if queryNodes[count] in TopEntropyNodes or isContainedAllTopEntropy:\n",
    "                for i in range (len(queryNodesClusterAggreation)):\n",
    "                    if( node in queryNodesClusterAggreation[i]):\n",
    "                        countMajority[i] = countMajority[i]+1\n",
    "                \n",
    "            if ( node in TopEntropyNodes and node != queryNodes[count]):\n",
    "                numOfHighEntropy = numOfHighEntropy+1\n",
    "                highEntropyNode.append(node)\n",
    "                currentProbNode = mt[queryNodes[count]][node]\n",
    "                #print ('highEntropyNode',queryNodes[count],node, currentProbNode)\n",
    "                \n",
    "                if ( maxProb < currentProbNode):\n",
    "                    maxProb = currentProbNode\n",
    "                    maxProbNode = node\n",
    "        if  (queryNodes[count] in TopEntropyNodes or isContainedAllTopEntropy):\n",
    "            maxMajority = 0#countMajority[0]\n",
    "            maxMajorityCluster = 0\n",
    "            for i in range (len(queryNodesClusterAggreation)):\n",
    "                if ( maxMajority < countMajority[i]):\n",
    "                        maxMajority = countMajority[i]\n",
    "                        maxMajorityCluster = i\n",
    "            iterable_cluster = list(cluster)\n",
    "            for i in range (len(queryNodesClusterAggreation)):\n",
    "                if ( i != maxMajorityCluster):\n",
    "                    for node in iterable_cluster:\n",
    "                        if( node in queryNodesClusterAggreation[i]):\n",
    "                            cluster.remove(node)\n",
    "            #print ('validCluster',cluster)\n",
    "        if ( numOfHighEntropy > 1 and not isContainedAllTopEntropy):\n",
    "            for node in highEntropyNode:\n",
    "                if( node != maxProbNode and node in cluster):\n",
    "                    cluster.remove(node)\n",
    "            #print ('numOfHighEntropy >1 -> validCluster',cluster,'maxProbNode:',maxProbNode)\n",
    "            exceptionNodes.append(queryNodes[count])\n",
    "        count = count+1\n",
    "        validCluster.append(cluster)\n",
    "        #print ('validCluster',validCluster)\n",
    "    return validCluster \n",
    "\n",
    "def ClusterAgglomertion(clusters, mt, num_cluster,Hinf,Pkcg):\n",
    "    #written by Phetsouvanh Silivanxay\n",
    "    aggClusters=[]\n",
    "    N = len(clusters)\n",
    "    probdistMatrix = [[0 for x in range(N)] for y in range(N)]\n",
    "    probdistMatrixMax = [[0 for x in range(N)] for y in range(N)]\n",
    "    connectMatrix = [[0 for x in range(N)] for y in range(N)]\n",
    "    for i in range  (N):\n",
    "        for j in range  (N):\n",
    "            if ( i != j):\n",
    "                Min = 1\n",
    "                Max = 0\n",
    "                Sum = 0\n",
    "                connect = 0\n",
    "                for nodeI in clusters[i]:\n",
    "                    for nodeJ in clusters[j]:\n",
    "                        if( Max < mt[nodeI][nodeJ]):\n",
    "                            Max = mt[nodeI][nodeJ]\n",
    "                        if( Min > mt[nodeI][nodeJ] and mt[nodeI][nodeJ]!=0):\n",
    "                            Min = mt[nodeI][nodeJ]\n",
    "                        if ( Pkcg[nodeI][nodeJ]!= 0):\n",
    "                            connect = Pkcg[nodeI][nodeJ]\n",
    "                        Sum = mt[nodeI][nodeJ]\n",
    "                avg = Sum / (len(clusters[i])*len(clusters[j]))\n",
    "                #print (i, j,'avg:', avg,'min:',min,'max:',max)\n",
    "                probdistMatrix[i][j] =  Min\n",
    "                probdistMatrixMax[i][j] = Max\n",
    "                connectMatrix[i][j] = connect\n",
    "    N = len(clusters)\n",
    "    \n",
    "    \n",
    "    clusterList = getBottomNClusters(Hinf,int(N),False,clusters)\n",
    "    TopEntropyClusterList = getBottomNClusters(Hinf,int(N*0.3),True,clusters)\n",
    "    randomList = random.sample(range(0,N),N)\n",
    "    queryNodesClusterAggreation = []\n",
    "    #clusterList = randomList\n",
    "    #print ('clusterList',clusterList)\n",
    "    #print ('TopEntropyClusterList',TopEntropyClusterList)\n",
    "    while(len(clusterList) > 0):\n",
    "        node = []\n",
    "        for acluster in clusterList:\n",
    "            node = acluster\n",
    "            break\n",
    "        clusterList.remove(node)\n",
    "        indxedClusters, maxIndex = findProbdistClusterWithQueryNode(probdistMatrix,num_cluster,node,N)\n",
    "        exceptionNodes = []\n",
    "        indxedClusters[maxIndex] = getValidQueryNodeCluster([indxedClusters[maxIndex]],TopEntropyClusterList,[node],exceptionNodes,probdistMatrix,queryNodesClusterAggreation)\n",
    "        copy_indexCluster = list(indxedClusters[maxIndex][0])\n",
    "        for index  in copy_indexCluster:\n",
    "            if (connectMatrix[node][index] ==0 and node != index):\n",
    "                indxedClusters[maxIndex][0].remove(index)\n",
    "                #print ('remove not connect',indxedClusters[maxIndex][0])\n",
    "        \n",
    "        \n",
    "        for i in range (len(indxedClusters)):\n",
    "            if ( i ==maxIndex):\n",
    "                #resultSet = set()\n",
    "                #print ('indxedClusters[i][0]',indxedClusters[i][0])\n",
    "                for index  in indxedClusters[i][0]:\n",
    "                    if ( index in clusterList):\n",
    "                        clusterList.remove(index)\n",
    "\n",
    "                aggClusters.append(set(indxedClusters[maxIndex][0]))\n",
    "        #print ('aggClusters',aggClusters)\n",
    "        aggClusters.extend(queryNodesClusterAggreation)\n",
    "        queryNodesClusterAggreation, includedSet = ClusterAggregation(aggClusters)\n",
    "        #print ('final queryNodesClusterAggreation:',queryNodesClusterAggreation)\n",
    "\n",
    "    MappingBackCluster = []\n",
    "    with out_comment:\n",
    "        clear_output(wait=True)\n",
    "        print ('seeds.append (',queryNodesClusterAggreation,')')\n",
    "    for acluster in queryNodesClusterAggreation:\n",
    "        resultSet = set()\n",
    "        for index in acluster:\n",
    "            resultSet = resultSet.union(clusters[index])\n",
    "        MappingBackCluster.append(resultSet)\n",
    "    \n",
    "    MappingBackCluster.extend(clusters)\n",
    "    queryNodesClusterAggreation, includedSet = ClusterAggregation(MappingBackCluster)\n",
    "    #print ('final MappingBackCluster:',queryNodesClusterAggreation)\n",
    "    return queryNodesClusterAggreation\n",
    "\n",
    "def ClusterAggregation(queryNodesCluster):\n",
    "    #written by Phetsouvanh Silivanxay\n",
    "    queryNodesClusterAggreation = []\n",
    "    includedSet = set()\n",
    "    while(len(queryNodesCluster) >0):\n",
    "        mergeCluster = []\n",
    "        for singleCluster in  queryNodesCluster:\n",
    "            mergeCluster = singleCluster\n",
    "            break\n",
    "        queryNodesCluster.remove(mergeCluster)\n",
    "        mergeClusterSet = set(mergeCluster)\n",
    "        removeClusters = []\n",
    "        for singleCluster in  queryNodesCluster:\n",
    "            singleClusterSet = set(singleCluster)\n",
    "            if (singleClusterSet.intersection(mergeClusterSet)):\n",
    "                mergeClusterSet = mergeClusterSet.union(singleClusterSet)\n",
    "                removeClusters.append(singleCluster)\n",
    "        for item in removeClusters:\n",
    "            queryNodesCluster.remove(item)\n",
    "        \n",
    "        queryNodesClusterAggreation.append(mergeClusterSet)\n",
    "        includedSet = includedSet.union(mergeClusterSet)\n",
    "    return queryNodesClusterAggreation,includedSet\n",
    "\n",
    "\n",
    "def findProbdistClusterWithQueryNode(probdistMatrix,num_cluster,node,N):\n",
    "    #written by Phetsouvanh Silivanxay\n",
    "    probdist = []\n",
    "        \n",
    "    for i in range  (N):\n",
    "        if (i != node):\n",
    "            probdist.append([probdistMatrix[node][i],0])\n",
    "        else:\n",
    "            probdist.append([0,0])\n",
    "    results =[]\n",
    "    if( N > 2):\n",
    "        agglomerative = cluster.AgglomerativeClustering(n_clusters=num_cluster, linkage=\"ward\",affinity='euclidean')\n",
    "        agglomerative.fit(probdist)   \n",
    "    \n",
    "        results.append(list(agglomerative.labels_))\n",
    "    else:\n",
    "        agglomerative = cluster.AgglomerativeClustering(n_clusters=1, linkage=\"ward\",affinity='euclidean')\n",
    "        agglomerative.fit(probdist)   \n",
    "    \n",
    "        results.append(list(agglomerative.labels_))\n",
    "    #print (node,'results',results)\n",
    "\n",
    "    avg_result = dict()\n",
    "    count_result = dict()\n",
    "    indxedClusters = []\n",
    "    for i in range (num_cluster):\n",
    "        avg_result[i] = 0\n",
    "        count_result[i] = 0\n",
    "        indxedClusters.append([])\n",
    "    for i in range (len(results[0])):\n",
    "        avg_result[results[0][i]] = avg_result[results[0][i]] +probdist[i][0]\n",
    "        count_result [results[0][i]] = count_result [results[0][i]]+1\n",
    "        indxedClusters[results[0][i]].append(i)\n",
    "    max = 0\n",
    "    maxIndex = 0\n",
    "    for i in range (num_cluster):\n",
    "        if ( count_result [i] != 0):\n",
    "            avg_result[i] = avg_result[i] / (count_result [i]+0.0)\n",
    "            if( max < avg_result[i] and avg_result[i] != 0 and avg_result[i] !=1) :\n",
    "                max = avg_result[i]\n",
    "                maxIndex = i\n",
    "            #print (i,avg_result[i], count_result[i])\n",
    "    if (max == 0 or max ==1):\n",
    "        indxedClusters[maxIndex] = []\n",
    "    indxedClusters[maxIndex].append(node)\n",
    "    #print ('mini result',maxIndex, indxedClusters[maxIndex])\n",
    "    return indxedClusters,maxIndex\n",
    "\n",
    "def isContainedAllTopEntropyNodes(TopEntropyNodes,queryNode,cluster):\n",
    "    #written by Phetsouvanh Silivanxay\n",
    "    contained = True\n",
    "    for node in cluster:\n",
    "        if( node != queryNode and node not in TopEntropyNodes):\n",
    "            contained = False\n",
    "    return contained\n",
    "\n",
    "\n",
    "def getBottomNClusters(H,n,rev,clusters):\n",
    "    #written by Phetsouvanh Silivanxay\n",
    "    H_dict= dict()\n",
    "    for i in range (len(H)):\n",
    "        H_dict[i] = H[i]\n",
    "    H_cluster_dict= dict()\n",
    "    for i in range ( len(clusters)):\n",
    "        H_cluster_dict[i] = 0\n",
    "        for node in clusters[i]:\n",
    "            H_cluster_dict[i] = H_cluster_dict[i]+H_dict[node]\n",
    "        H_cluster_dict[i] = H_cluster_dict[i] / len(clusters[i])\n",
    "            \n",
    "    count = 0\n",
    "    output = []\n",
    "    for key, value in sorted(H_cluster_dict.items(), key=operator.itemgetter(1),reverse=rev):\n",
    "        if(count == n):\n",
    "            break\n",
    "        output.append(key)\n",
    "        count = count+1\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "function code_toggle() {\n",
       "    if (code_shown){\n",
       "      $('div.input').hide('300');\n",
       "      $('#toggleButton').val('Show Code')\n",
       "    } else {\n",
       "      $('div.input').show('300');\n",
       "      $('#toggleButton').val('Hide Code')\n",
       "    }\n",
       "    code_shown = !code_shown\n",
       "  }\n",
       "\n",
       "  $( document ).ready(function(){\n",
       "    code_shown=false;\n",
       "    $('div.input').hide()\n",
       "  });\n",
       "  $(document).ready(function(){\n",
       "    $('div.prompt').hide();\n",
       "    $('div.back-to-top').hide();\n",
       "    $('nav#menubar').hide();\n",
       "    $('.breadcrumb').hide();\n",
       "    $('.hidden-print').hide();\n",
       "  });\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#http://chris-said.io/2016/02/13/how-to-make-polished-jupyter-presentations-with-optional-code-visibility/\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "function code_toggle() {\n",
    "    if (code_shown){\n",
    "      $('div.input').hide('300');\n",
    "      $('#toggleButton').val('Show Code')\n",
    "    } else {\n",
    "      $('div.input').show('300');\n",
    "      $('#toggleButton').val('Hide Code')\n",
    "    }\n",
    "    code_shown = !code_shown\n",
    "  }\n",
    "\n",
    "  $( document ).ready(function(){\n",
    "    code_shown=false;\n",
    "    $('div.input').hide()\n",
    "  });\n",
    "  $(document).ready(function(){\n",
    "    $('div.prompt').hide();\n",
    "    $('div.back-to-top').hide();\n",
    "    $('nav#menubar').hide();\n",
    "    $('.breadcrumb').hide();\n",
    "    $('.hidden-print').hide();\n",
    "  });\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>\n",
    "''')"
   ]
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "grid_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 10,
      "defaultCellHeight": 20,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
